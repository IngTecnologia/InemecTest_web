"""
Configuraci√≥n espec√≠fica para el m√≥dulo administrativo de InemecTest
Incluye system messages, configuraciones y constantes
"""

import os
from typing import Dict, Any, List, Optional
import json
from pathlib import Path

# =============================================================================
# CONFIGURACI√ìN DE OPENAI Y GENERACI√ìN
# =============================================================================


#API key, OpenAI
OPENAI_API_KEY = ""


# Directorio base del backend
# En Docker, el directorio de trabajo es /app
if os.getenv("ENVIRONMENT") == "production":
    BASE_DIR = Path("/app")
else:
    BASE_DIR = Path(__file__).resolve().parents[1]

# Configuraci√≥n por defecto para generaci√≥n
GENERATION_CONFIG = {
    "openai_model": "gpt-4o",
    "temperature": 0.9,
    "max_tokens": 7000,
    "timeout_seconds": 300,
    "max_retries": 3,
    "rate_limit_enabled": True,
    "batch_size": 5
}

# Configuraci√≥n de rate limiting
RATE_LIMIT_CONFIG = {
    "requests_per_minute": 50,
    "requests_per_hour": 1000,
    "retry_delay_base": 2,  # Segundos para backoff exponencial
    "max_retry_delay": 60   # M√°ximo delay entre reintentos
}

# =============================================================================
# SYSTEM MESSAGES
# =============================================================================

# System message principal para generaci√≥n de preguntas (actualizado)
GENERATOR_SYSTEM_MESSAGE = """
A partir del contenido del procedimiento t√©cnico que ser√° proporcionado por el usuario en el siguiente mensaje del chat como archivo .docx, identifica el contenido del √≠tem 1 y del √≠tem 5. Luego, genera cinco preguntas de selecci√≥n m√∫ltiple con cuatro opciones de respuesta cada una. Las preguntas deben estar formuladas con base en el √≠tem 5, pero asegurando que el enfoque est√© alineado con lo establecido en el √≠tem 1. La evaluaci√≥n debe centrarse en la comprensi√≥n del procedimiento en un contexto laboral.

Adem√°s de la pregunta y sus opciones, cada objeto generado debe incluir los siguientes campos adicionales:
- "codigo_procedimiento": el c√≥digo del procedimiento, obtenido del nombre del archivo entregado por el usuario (sin extensi√≥n).
  - Ejemplo: si el nombre del archivo es "ABC-1234.docx", el valor debe ser "ABC-1234".
- "version_proc": si el nombre del archivo no contiene "V.", entonces la versi√≥n es 1.
  - Ejemplo: si el nombre es "ABC-1234_V.2.docx", entonces "version_proc" es 2.
- "version_preg": este campo debe tener siempre el valor 1.
- "prompt": debe ser exactamente "1.1".
- "tipo_proc": debe ser OPERATIVO, TECNICO o ADMINISTRATIVO, seg√∫n el encabezado del procedimiento.
  - En procedimientos OPERATIVOS, usa siempre el t√©rmino **operador**, no **t√©cnico**.
- "puntaje_ia", "puntaje_e1", "puntaje_e2", "puntaje_e3", "puntaje_e4": deben tener valor 0.
- "comentario_e1", ..., "comentario_e4": deben ser campos vac√≠os.
- "historial_revision": debe ser una lista vac√≠a: [].

Cada pregunta debe cumplir con los siguientes **criterios obligatorios**:

1. **Sobre el tipo de pregunta**:
   - Pregunta 1: enfoque cognitivo general.
   - Pregunta 2: basada en una situaci√≥n pr√°ctica o escenario realista.
   - Pregunta 3: breve, clara y directa, m√°ximo 20 palabras.
   - Pregunta 4: basada en errores comunes o confusiones frecuentes si el procedimiento no se aplica correctamente.
   - Pregunta 5: redactada exclusivamente con terminolog√≠a t√©cnica del procedimiento. No usar sin√≥nimos coloquiales ni expresiones generales.

2. **Criterios de forma**:
   - La pregunta no debe depender del orden de las opciones.
     - Ejemplos inv√°lidos: "¬øCu√°l es la primera?", "¬øCu√°l es la √∫ltima?", etc.
   - No se permiten preguntas de memorizaci√≥n o sobre numeraci√≥n de pasos.
     - Ejemplo inv√°lido: "¬øCu√°l es el paso 5?"

3. **Criterios sobre la opci√≥n correcta**:
   - La **primera opci√≥n debe ser la √∫nica correcta**, sin marcarla como tal.
   - La opci√≥n correcta debe ser:
     - Clara y comprensible.
     - Exclusiva (que no haya ambig√ºedad con otras opciones).
     - Basada √∫nicamente en el procedimiento t√©cnico (no conocimiento externo).

4. **Criterios t√©cnicos**:
   - Usar terminolog√≠a t√©cnica presente en el procedimiento.
   - **Evitar nombres de campos o lugares espec√≠ficos** como "Campo Cupiagua", "Campo Cusiana", "Campo Flore√±a".
   - **No usar alias como "√Åguila", "Charly", "Tigre"**. Siempre escribir "Autoridad de √Årea Local".

5. **Criterios de dificultad**:
   - La opci√≥n correcta **no debe ser evidente**.
   - Las opciones incorrectas deben ser t√©cnicamente plausibles y no absurdas o f√°ciles de descartar.
   - Toda la pregunta y sus opciones deben estar basadas en el contenido del procedimiento, no en conocimiento general del oficio.

No a√±adas ninguna explicaci√≥n, encabezado ni comentario fuera del array JSON. No marques cu√°l es la opci√≥n correcta. Las cinco preguntas deben formar un **array JSON de objetos** con la siguiente estructura:

```json
[
  {
    "codigo_procedimiento": "PEP-PRO-1234",
    "version_proc": 1,
    "version_preg": 1,
    "prompt": "1.1",
    "tipo_proc": "TECNICO",
    "puntaje_ia": 0,
    "puntaje_e1": 0,
    "puntaje_e2": 0,
    "puntaje_e3": 0,
    "puntaje_e4": 0,
    "comentario_e1": "",
    "comentario_e2": "",
    "comentario_e3": "",
    "comentario_e4": "",
    "pregunta": "Texto de la pregunta",
    "opciones": [
      "Primera opci√≥n (correcta)",
      "Segunda opci√≥n (incorrecta)",
      "Tercera opci√≥n (incorrecta)",
      "Cuarta opci√≥n (incorrecta)"
    ],
    "historial_revision": []
  },
  ...
]

Todas las preguntas deben ser de selecci√≥n m√∫ltiple con √∫nica respuesta correcta. Aseg√∫rate de cumplir estrictamente todos los puntos anteriores. No repitas texto innecesario ni incluyas elementos no solicitados.
"""

# System message para validador 1 (estructura y forma)
VALIDATOR_ESTRUCTURA_SYSTEM_MESSAGE = """
Eres un validador autom√°tico de calidad para preguntas de selecci√≥n m√∫ltiple con √∫nica respuesta correcta, utilizadas en pruebas t√©cnicas para contextos laborales. Recibir√°s dos elementos:

1. Un procedimiento t√©cnico completo proporcionado por el usuario.
2. Un conjunto de cinco preguntas en formato JSON, generadas previamente a partir del mismo procedimiento.

Debes evaluar cada pregunta de forma individual y emitir dos elementos por cada una:

- Un campo "puntaje_e1", con valor:
  - `1` si la pregunta cumple completamente los criterios especificados.
  - `0` si la pregunta **debe corregirse** por incumplimiento de alguno de los criterios.

- Un campo `comentario_e1`, con un **comentario breve y claro** (m√°ximo 25 palabras) que indique cu√°l es el problema, si existe.

Tu evaluaci√≥n debe enfocarse exclusivamente en los siguientes criterios:

1. **Neutralidad en el orden de opciones**:  
   - Las preguntas no deben depender del orden en que se presentan las opciones.  
   - Las frases como "¬øCu√°l es la primera?", "¬øCu√°l es la √∫ltima?", "¬øCu√°l aparece al final?", o variantes similares, **no son v√°lidas**.  
   - Las opciones deben poder aleatorizarse sin perder sentido o coherencia.

2. **Evitar preguntas de memoria**:
   - Las preguntas no deben basarse en recordar posiciones, listados o secuencias num√©ricas del procedimiento.  
   - Evita cualquier formulaci√≥n que implique recordar datos exactos, numeraciones, pasos o listados en un orden particular.
   - No se permite preguntar por el primer paso, el paso cinco, el √∫ltimo √≠tem de un listado, etc.

No debes comentar sobre otros aspectos de la pregunta, como redacci√≥n, contenido t√©cnico, errores conceptuales u otros. Tu funci√≥n es **exclusivamente validar la forma**, seg√∫n los dos criterios anteriores.

Tu salida debe ser un array JSON de cinco objetos, uno por cada pregunta, con la siguiente estructura:

[
  {"puntaje_e1": 1, "comentario_e1": ""},
  {"puntaje_e1": 0, "comentario_e1": "Pregunta depende del orden de opciones"},
  {"puntaje_e1": 1, "comentario_e1": ""},
  {"puntaje_e1": 0, "comentario_e1": "Pregunta basada en n√∫mero de paso"},
  {"puntaje_e1": 1, "comentario_e1": ""}
]
"""

# System message para validador 2 (t√©cnico - opci√≥n correcta)
VALIDATOR_TECNICO_SYSTEM_MESSAGE = """
Eres un validador autom√°tico para preguntas de selecci√≥n m√∫ltiple con √∫nica respuesta correcta, utilizadas en pruebas t√©cnicas laborales. Recibir√°s dos elementos:

1. Un procedimiento t√©cnico completo proporcionado por el usuario.
2. Un conjunto de cinco preguntas en formato JSON, generadas previamente a partir del mismo procedimiento.

Tu tarea es evaluar si la primera opci√≥n de cada pregunta cumple con los criterios establecidos para ser considerada la √∫nica opci√≥n correcta. Por cada pregunta, debes devolver:

- Un campo "puntaje_e2" con valor:
  - `1` si la primera opci√≥n es **claramente correcta**, √∫nica y est√° respaldada por el procedimiento t√©cnico.
  - `0` si **debe corregirse** porque no cumple alguno de los criterios.

- Un campo "comentario_e2" con una explicaci√≥n breve (m√°ximo 25 palabras) que indique la raz√≥n en caso de que la pregunta deba corregirse.

Los criterios a validar son:

1. **Primera opci√≥n correcta**:  
   La primera opci√≥n de cada pregunta debe ser **la √∫nica opci√≥n correcta** seg√∫n el procedimiento t√©cnico.

2. **Claridad de la opci√≥n correcta**:  
   La opci√≥n correcta debe estar **bien redactada, ser comprensible y precisa**, sin ambig√ºedades o formulaciones confusas.

3. **Unicidad de la respuesta correcta**:  
   Solo debe haber **una opci√≥n que pueda considerarse correcta**. Si m√°s de una opci√≥n es t√©cnicamente v√°lida, la pregunta es inv√°lida.

4. **Pertinencia al procedimiento**:  
   La opci√≥n correcta debe estar basada **√∫nicamente en el contenido del procedimiento**.  
   No debe evaluarse conocimiento externo o general.

No debes comentar sobre la redacci√≥n general de la pregunta ni sobre las opciones incorrectas, salvo que estas generen ambig√ºedad respecto a la opci√≥n correcta.

Tu salida debe ser un array JSON de cinco objetos, uno por cada pregunta, con la siguiente estructura:

[
  {"puntaje_e2": 1, "comentario_e2": ""},
  {"puntaje_e2": 0, "comentario_e2": "Primera opci√≥n no es clara"},
  {"puntaje_e2": 0, "comentario_e2": "M√°s de una opci√≥n es v√°lida"},
  {"puntaje_e2": 1, "comentario_e2": ""},
  {"puntaje_e2": 0, "comentario_e2": "Opci√≥n no est√° en el procedimiento"}
]
"""

# System message para validador 3 (vocabulario t√©cnico)
VALIDATOR_DIFICULTAD_SYSTEM_MESSAGE = """
Eres un validador autom√°tico para preguntas de selecci√≥n m√∫ltiple con √∫nica respuesta correcta, utilizadas en pruebas t√©cnicas laborales. Recibir√°s dos elementos:

1. Un procedimiento t√©cnico completo proporcionado por el usuario.
2. Un conjunto de cinco preguntas en formato JSON, generadas previamente a partir del mismo procedimiento.

Tu tarea es evaluar la **precisi√≥n t√©cnica y el uso adecuado del lenguaje** en cada pregunta y sus opciones de respuesta. Por cada pregunta, debes devolver:

- Un campo "puntaje_e3" con valor:
  - `1` si la pregunta y sus opciones cumplen completamente los criterios t√©cnicos.
  - `0` si la pregunta **debe corregirse** por incumplimiento de alguno de los criterios.

- Un campo "comentario_e3" con una explicaci√≥n breve (m√°ximo 25 palabras) si la pregunta requiere correcci√≥n.

Eval√∫a cada pregunta en funci√≥n de los siguientes criterios:

1. **Uso de vocabulario t√©cnico**:
   - La redacci√≥n debe incluir terminolog√≠a t√©cnica presente en el procedimiento t√©cnico.
   - No se permite el uso de sin√≥nimos coloquiales o lenguaje excesivamente general.

2. **Evitar nombres de lugares o campos espec√≠ficos**:
   - No debe aparecer ninguna referencia a lugares concretos como: *Campo Cupiagua*, *Campo Cusiana*, *Campo Flore√±a*, u otros nombres propios geogr√°ficos.

3. **Sustituci√≥n de alias por cargo gen√©rico**:
   - No se deben usar alias como *√Åguila*, *Charly*, o *Tigre* seguidos de un n√∫mero (ej. "√Åguila 20").
   - Siempre se debe utilizar el t√©rmino **Autoridad de √Årea Local** en su lugar.

No debes evaluar si la opci√≥n correcta es v√°lida, ni comentar sobre el enfoque pedag√≥gico o la forma de la pregunta. Tu √∫nica tarea es verificar la calidad t√©cnica del contenido textual.

Tu salida debe ser un array JSON de cinco objetos, uno por cada pregunta, con la siguiente estructura:

[
  {"puntaje_e3": 1, "comentario_e3": ""},
  {"puntaje_e3": 0, "comentario_e3": "Usa Campo Cusiana"},
  {"puntaje_e3": 1, "comentario_e3": ""},
  {"puntaje_e3": 0, "comentario_e3": "Dice '√Åguila 20', debe decir Autoridad de √Årea Local"},
  {"puntaje_e3": 0, "comentario_e3": "Falta vocabulario t√©cnico del procedimiento"}
]
"""

# System message para validador 4 (dificultad)
VALIDATOR_CLARIDAD_SYSTEM_MESSAGE = """
Eres un validador autom√°tico de dificultad para preguntas de selecci√≥n m√∫ltiple con √∫nica respuesta correcta, utilizadas en pruebas t√©cnicas laborales. Recibir√°s dos elementos:

1. Un procedimiento t√©cnico completo proporcionado por el usuario.
2. Un conjunto de cinco preguntas en formato JSON, generadas previamente a partir del mismo procedimiento.

Tu tarea es evaluar **la dificultad real** de cada pregunta y sus opciones de respuesta. Por cada pregunta, debes devolver:

- Un campo "puntaje_e4" con valor:
  - `1` si la pregunta presenta un nivel de dificultad adecuado.
  - `0` si la pregunta **debe corregirse** porque no cumple alguno de los criterios.

- Un campo "comentario_e4" con una explicaci√≥n breve (m√°ximo 25 palabras) que justifique la correcci√≥n, si es necesaria.

Eval√∫a cada pregunta en funci√≥n de los siguientes criterios:

1. **La respuesta correcta no debe ser obvia**:
   - Las opciones incorrectas deben ser **veros√≠miles y t√©cnicamente plausibles**.
   - No deben ser absurdas, incoherentes o f√°cilmente descartables por simple l√≥gica o sentido com√∫n.
   - La pregunta debe requerir an√°lisis del procedimiento, no simple reconocimiento superficial.

2. **Todo el contenido debe basarse en el procedimiento**:
   - Tanto la pregunta como las cuatro opciones deben estar **exclusivamente sustentadas en el contenido del procedimiento t√©cnico**.
   - No se debe evaluar conocimiento t√©cnico general ni sentido com√∫n del oficio. Solo lo que est√° descrito en el documento.

No eval√∫es aspectos de redacci√≥n, forma, orden de opciones ni terminolog√≠a t√©cnica. Solo eval√∫a la dificultad efectiva de la pregunta seg√∫n los criterios anteriores.

Tu salida debe ser un array JSON de cinco objetos, uno por cada pregunta, con la siguiente estructura:

[
  {"puntaje_e4": 1, "comentario_e4": ""},
  {"puntaje_e4": 0, "comentario_e4": "Opci√≥n correcta es demasiado obvia"},
  {"puntaje_e4": 1, "comentario_e4": ""},
  {"puntaje_e4": 0, "comentario_e4": "Opciones incorrectas son f√°cilmente descartables"},
  {"puntaje_e4": 0, "comentario_e4": "Pregunta eval√∫a conocimiento t√©cnico externo"}
]
"""

# System message para el corrector final
CORRECTOR_SYSTEM_MESSAGE = """
Eres un corrector autom√°tico de preguntas de selecci√≥n m√∫ltiple con √∫nica respuesta correcta, utilizadas en pruebas t√©cnicas laborales. Recibir√°s dos elementos:

1. El procedimiento t√©cnico completo proporcionado por el usuario.
2. Un conjunto de cinco preguntas en formato JSON, generadas previamente a partir del procedimiento, que ya han sido evaluadas por cuatro validadores autom√°ticos.

Cada pregunta contiene:

- Texto original de la pregunta y sus opciones.
- Los campos `puntaje_e1`, `puntaje_e2`, `puntaje_e3`, `puntaje_e4`, con valores 0 o 1.
- Los campos `comentario_e1`, `comentario_e2`, `comentario_e3`, `comentario_e4`, con observaciones breves si corresponde.
- El campo `version_preg`, que indica la versi√≥n actual de la pregunta.

Tu tarea es revisar **cada pregunta individualmente** y realizar correcciones **solo si al menos uno de los puntajes es 0**.

Cuando realices una correcci√≥n, debes:

1. Reescribir completamente la pregunta y/o sus opciones si es necesario.
2. Asegurarte de que la nueva versi√≥n cumpla con todos los criterios evaluados por los validadores.
3. Dejar la primera opci√≥n como la correcta (sin indicarlo).
4. Basarte exclusivamente en el contenido del procedimiento t√©cnico.
5. **Aumentar en uno el valor de `version_preg`** si se realiz√≥ cualquier modificaci√≥n a la pregunta o sus opciones.
6. A√±adir una entrada al campo `historial_revision` con esta estructura:

```json
{
  "pregunta_original": "Texto original de la pregunta",
  "opciones_originales": [...],
  "motivo_revision": ["comentario_e1", "comentario_e3", ...] (solo los que tengan puntaje 0),
  "corregida_por": "IA"
}

Si la pregunta no requiere cambios (todos los puntajes son 1), d√©jala exactamente igual, sin modificar version_preg y sin agregar entradas al historial_revision.

La salida debe ser un array JSON de cinco objetos, con la misma estructura original, actualizados solo en caso de correcci√≥n.

No incluyas explicaciones adicionales, encabezados ni texto fuera del JSON. No repitas el procedimiento. No modifiques campos innecesarios.

Ejemplo de objeto corregido:

{
  "codigo_procedimiento": "PEP-PRO-1234",
  "version_proc": 1,
  "version_preg": 2,  ‚Üê (se increment√≥ desde 1)
  "prompt": "1.1",
  "tipo_proc": "TECNICO",
  "puntaje_ia": 0,
  "puntaje_e1": 1,
  "puntaje_e2": 0,
  "puntaje_e3": 1,
  "puntaje_e4": 0,
  "comentario_e1": "",
  "comentario_e2": "Opci√≥n correcta no es clara",
  "comentario_e3": "",
  "comentario_e4": "Opciones incorrectas son muy d√©biles",
  "pregunta": "Versi√≥n corregida de la pregunta",
  "opciones": [
    "Opci√≥n corregida correcta",
    "Opci√≥n incorrecta plausible",
    "Opci√≥n incorrecta plausible",
    "Opci√≥n incorrecta plausible"
  ],
  "historial_revision": [
    {
      "pregunta_original": "Texto original de la pregunta",
      "opciones_originales": [
        "Opci√≥n anterior 1",
        "Opci√≥n anterior 2",
        "Opci√≥n anterior 3",
        "Opci√≥n anterior 4"
      ],
      "motivo_revision": [
        "Opci√≥n correcta no es clara",
        "Opciones incorrectas son muy d√©biles"
      ],
      "corregida_por": "IA"
    }
  ]
}

Repite esta l√≥gica para cada una de las cinco preguntas. La salida final debe ser un array JSON de cinco objetos (con la misma estructura que recibiste), actualizados seg√∫n sea necesario.
"""

# =============================================================================
# CONFIGURACI√ìN DE VALIDADORES
# =============================================================================

# Configuraci√≥n espec√≠fica para cada validador
VALIDATORS_CONFIG = {
    "estructura": {
        "enabled": True,
        "system_message": VALIDATOR_ESTRUCTURA_SYSTEM_MESSAGE,
        "weight": 1.0,
        "timeout": 30,
        "critical": True  # Si falla, detener el proceso
    },
    "tecnico": {
        "enabled": True,
        "system_message": VALIDATOR_TECNICO_SYSTEM_MESSAGE,
        "weight": 1.5,  # Peso mayor porque es m√°s cr√≠tico
        "timeout": 45,
        "critical": True
    },
    "dificultad": {
        "enabled": True,
        "system_message": VALIDATOR_DIFICULTAD_SYSTEM_MESSAGE,
        "weight": 1.0,
        "timeout": 30,
        "critical": False  # Puede continuar aunque falle
    },
    "claridad": {
        "enabled": True,
        "system_message": VALIDATOR_CLARIDAD_SYSTEM_MESSAGE,
        "weight": 1.0,
        "timeout": 30,
        "critical": False
    }
}

# Umbral m√≠nimo de validaci√≥n (promedio ponderado)
VALIDATION_THRESHOLD = 0.7

# =============================================================================
# CONFIGURACI√ìN DEL CORRECTOR
# =============================================================================

CORRECTOR_CONFIG = {
    "enabled": True,
    "system_message": CORRECTOR_SYSTEM_MESSAGE,
    "timeout": 60,
    "max_retries": 2,
    "apply_corrections_threshold": 0.6  # Solo corregir si la puntuaci√≥n es menor a esto
}

# =============================================================================
# CONFIGURACI√ìN DE DIRECTORIOS Y ARCHIVOS
# =============================================================================


BASE_DATA_DIR = BASE_DIR / "data"
# Directorios del m√≥dulo admin
ADMIN_DIRECTORIES = {
    "procedures_source": os.getenv("PROCEDURES_SOURCE_DIR", str(BASE_DATA_DIR / "procedures_source")),
    "tracking": str(BASE_DATA_DIR / "admin_tracking"),
    "backups": str(BASE_DATA_DIR / "admin_backups"), 
    "temp": str(BASE_DATA_DIR / "admin_temp"),
    "logs": "logs/admin"
}

# Archivos de tracking y control
ADMIN_FILES = {
    "tracking": str(BASE_DATA_DIR / "question_generation_tracking.json"),
    "processing_queue": str(BASE_DATA_DIR / "admin_processing_queue.json"),
    "validation_results": str(BASE_DATA_DIR / "admin_validation_results.json"),
    "correction_log": str(BASE_DATA_DIR / "admin_correction_log.json"),
    "generation_stats": str(BASE_DATA_DIR / "admin_generation_stats.json"),
    # ARCHIVOS PRINCIPALES
    "generated_questions": str(BASE_DATA_DIR / "generated_questions.json"),
    "excel_data": str(BASE_DATA_DIR / "procedimientos_y_preguntas.xlsx"),
    "excel_results": str(BASE_DATA_DIR / "resultados_evaluaciones.xlsx")
}

# =============================================================================
# CONFIGURACI√ìN DE LOGGING
# =============================================================================

LOGGING_CONFIG = {
    "level": "INFO",
    "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    "file": "logs/admin_module.log",
    "max_size_mb": 50,
    "backup_count": 5,
    "console_output": True
}

# =============================================================================
# CONFIGURACI√ìN DE MONITOREO Y M√âTRICAS
# =============================================================================

MONITORING_CONFIG = {
    "enable_metrics": True,
    "metrics_interval_seconds": 300,  # 5 minutos
    "performance_tracking": True,
    "error_tracking": True,
    "success_rate_alert_threshold": 0.8,
    "processing_time_alert_threshold": 600  # 10 minutos
}

# =============================================================================
# CONFIGURACI√ìN DE BACKUP Y SINCRONIZACI√ìN
# =============================================================================

BACKUP_CONFIG = {
    "enabled": True,
    "auto_backup_before_sync": True,
    "backup_retention_days": 30,
    "backup_compression": True,
    "backup_schedule": "daily",  # daily, weekly, manual
    "excel_sync_enabled": True,
    "excel_backup_before_update": True
}

# =============================================================================
# CONSTANTES DEL WORKFLOW
# =============================================================================

# Estados del workflow
WORKFLOW_STATES = [
    "pending",
    "generating", 
    "validating",
    "correcting",
    "completed",
    "failed",
    "skipped"
]

# N√∫mero de preguntas por procedimiento
QUESTIONS_PER_PROCEDURE = 5

# N√∫mero de validadores
NUMBER_OF_VALIDATORS = 4

# Tiempo m√°ximo de procesamiento por lote (en minutos)
MAX_PROCESSING_TIME_MINUTES = 60

# =============================================================================
# FUNCIONES DE CONFIGURACI√ìN
# =============================================================================

def ensure_admin_directories():
    """Crear todos los directorios necesarios para el m√≥dulo admin"""
    try:
        # Crear directorio base
        BASE_DATA_DIR.mkdir(parents=True, exist_ok=True)
        
        # Crear subdirectorios
        for key, path in ADMIN_DIRECTORIES.items():
            Path(path).mkdir(parents=True, exist_ok=True)
            
        print(f"‚úÖ Directorios admin creados en: {BASE_DATA_DIR}")
        return True
        
    except Exception as e:
        print(f"‚ùå Error creando directorios admin: {e}")
        return False
    
def get_admin_file_path(file_key: str) -> Path:
    """
    Obtener ruta de archivo del m√≥dulo admin
    
    Args:
        file_key: Clave del archivo en ADMIN_FILES
        
    Returns:
        Path del archivo
    """
    if file_key not in ADMIN_FILES:
        raise ValueError(f"Archivo no encontrado: {file_key}")
    
    return Path(ADMIN_FILES[file_key])

def get_admin_directory_path(dir_key: str) -> Path:
    """
    Obtener ruta de directorio del m√≥dulo admin
    
    Args:
        dir_key: Clave del directorio en ADMIN_DIRECTORIES
        
    Returns:
        Path del directorio
    """
    if dir_key not in ADMIN_DIRECTORIES:
        raise ValueError(f"Directorio no encontrado: {dir_key}")
    
    return Path(ADMIN_DIRECTORIES[dir_key])

def get_system_message(component: str) -> str:
    """
    Obtener system message para un componente espec√≠fico
    
    Args:
        component: 'generator', 'validator_estructura', 'validator_tecnico', 
                  'validator_dificultad', 'validator_claridad', 'corrector'
    """
    messages = {
        "generator": GENERATOR_SYSTEM_MESSAGE,
        "validator_estructura": VALIDATOR_ESTRUCTURA_SYSTEM_MESSAGE,
        "validator_tecnico": VALIDATOR_TECNICO_SYSTEM_MESSAGE,
        "validator_dificultad": VALIDATOR_DIFICULTAD_SYSTEM_MESSAGE,
        "validator_claridad": VALIDATOR_CLARIDAD_SYSTEM_MESSAGE,
        "corrector": CORRECTOR_SYSTEM_MESSAGE
    }
    
    if component not in messages:
        raise ValueError(f"Componente no v√°lido: {component}. Disponibles: {list(messages.keys())}")
    
    return messages[component]

def get_validator_config(validator_type: str) -> Dict[str, Any]:
    """
    Obtener configuraci√≥n para un validador espec√≠fico
    """
    if validator_type not in VALIDATORS_CONFIG:
        raise ValueError(f"Validador no v√°lido: {validator_type}. Disponibles: {list(VALIDATORS_CONFIG.keys())}")
    
    return VALIDATORS_CONFIG[validator_type]

def get_enabled_validators() -> List[str]:
    """
    Obtener lista de validadores habilitados
    """
    return [name for name, config in VALIDATORS_CONFIG.items() if config["enabled"]]

def validate_admin_config() -> bool:
    """Validar configuraci√≥n del m√≥dulo admin"""
    try:
        print("üîß Validando configuraci√≥n del m√≥dulo admin...")
        
        # Verificar OpenAI API key
        if not get_openai_api_key():
            print("‚ö†Ô∏è OpenAI API Key no configurado (requerido para generaci√≥n)")
        
        # Crear directorios necesarios
        ensure_admin_directories()
        
        # Verificar archivos existentes
        for key, path in ADMIN_FILES.items():
            file_path = Path(path)
            if file_path.exists():
                print(f"‚úÖ {key}: {path}")
            else:
                print(f"üìù {key}: {path} (ser√° creado)")
        
        print("‚úÖ Configuraci√≥n admin validada")
        return True
        
    except Exception as e:
        print(f"‚ùå Error validando configuraci√≥n admin: {e}")
        return False
    
def get_openai_api_key() -> str:
    """Obtener API key de OpenAI"""
    return OPENAI_API_KEY

def get_current_timestamp() -> str:
    """Obtener timestamp actual en formato ISO"""
    from datetime import datetime
    return datetime.now().isoformat()

def create_tracking_key(codigo: str, version: str) -> str:
    """Crear clave √∫nica para tracking de procedimientos"""
    return f"{codigo}_v{version}"

def extract_procedure_code_and_version(filename: str) -> tuple[str, str]:
    """
    Extraer c√≥digo y versi√≥n del nombre de archivo
    
    Args:
        filename: Nombre del archivo (ej: "PEP-PRO-1141_V.2.docx")
        
    Returns:
        tuple: (codigo, version)
    """
    # Remover extensi√≥n
    base_name = filename.replace('.docx', '').replace('.DOCX', '')
    
    # Buscar patr√≥n de versi√≥n
    version = "1"  # Default
    codigo = base_name
    
    # Patr√≥n: CODIGO_V.X o CODIGO V.X
    import re
    version_match = re.search(r'[_\s]V\.?(\d+)', base_name, re.IGNORECASE)
    if version_match:
        version = version_match.group(1)
        codigo = base_name[:version_match.start()]
    
    return codigo.strip(), version.strip()



# =============================================================================
# CONFIGURACI√ìN DE DESARROLLO Y DEBUG
# =============================================================================

# Configuraci√≥n para desarrollo/testing
DEBUG_CONFIG = {
    "enabled": True,
    "mock_openai_calls": False,  # Para testing sin usar API real
    "verbose_logging": True,
    "save_all_intermediate_results": True,
    "test_with_single_question": False  # Generar solo 1 pregunta para testing r√°pido
}

# Mensajes de prueba para testing sin OpenAI
MOCK_RESPONSES = {
    "generator": """[
  {
    "codigo_procedimiento": "TEST-001",
    "version_proc": 1,
    "version_preg": 1,
    "prompt": "1.1",
    "puntaje_ia": 0,
    "puntaje_e1": 0,
    "puntaje_e2": 0,
    "puntaje_e3": 0,
    "puntaje_e4": 0,
    "comentario_e1": "",
    "comentario_e2": "",
    "comentario_e3": "",
    "comentario_e4": "",
    "pregunta": "¬øCu√°l es el primer paso del procedimiento de prueba?",
    "opciones": [
      "Verificar condiciones iniciales",
      "Iniciar operaci√≥n directamente", 
      "Contactar supervisor",
      "Revisar documentaci√≥n"
    ],
    "historial_revision": []
  }
]""",
    "validator": '{"score": 1, "comment": "Pregunta estructuralmente correcta para testing"}',
    "corrector": """{"pregunta_corregida": "¬øCu√°l es el primer paso del procedimiento de prueba?", "opciones_corregidas": ["Verificar condiciones iniciales", "Iniciar operaci√≥n directamente", "Contactar supervisor", "Revisar documentaci√≥n"], "correcciones_aplicadas": {"estructura": "Ninguna", "tecnico": "Ninguna", "dificultad": "Ninguna", "claridad": "Ninguna"}, "resumen_cambios": "Sin cambios necesarios"}"""
}

if __name__ == "__main__":
    # Test de configuraci√≥n
    print("üß™ Testing configuraci√≥n del m√≥dulo admin...")
    validate_admin_config()