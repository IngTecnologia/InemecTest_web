"""
ConfiguraciÃ³n especÃ­fica para el mÃ³dulo administrativo de InemecTest
Incluye system messages, configuraciones y constantes
"""

import os
from typing import Dict, Any, List, Optional
import json
from pathlib import Path

# =============================================================================
# CONFIGURACIÃ“N DE OPENAI Y GENERACIÃ“N
# =============================================================================


#API key, OpenAI
OPENAI_API_KEY = ""


# Directorio base del backend
# En Docker, el directorio de trabajo es /app
if os.getenv("ENVIRONMENT") == "production":
    BASE_DIR = Path("/app")
else:
    BASE_DIR = Path(__file__).resolve().parents[1]

# ConfiguraciÃ³n por defecto para generaciÃ³n
GENERATION_CONFIG = {
    "openai_model": "gpt-4o",
    "temperature": 0.9,
    "max_tokens": 7000,
    "timeout_seconds": 300,
    "max_retries": 3,
    "rate_limit_enabled": True,
    "batch_size": 5
}

# ConfiguraciÃ³n de rate limiting
RATE_LIMIT_CONFIG = {
    "requests_per_minute": 50,
    "requests_per_hour": 1000,
    "retry_delay_base": 2,  # Segundos para backoff exponencial
    "max_retry_delay": 60   # MÃ¡ximo delay entre reintentos
}

# =============================================================================
# SYSTEM MESSAGES
# =============================================================================

# System message principal para generaciÃ³n de preguntas (actualizado)
GENERATOR_SYSTEM_MESSAGE = """
A partir del contenido del procedimiento tÃ©cnico que serÃ¡ proporcionado por el usuario en el siguiente mensaje del chat como archivo .docx, identifica el contenido del Ã­tem 1 y del Ã­tem 5. Luego, genera cinco preguntas de selecciÃ³n mÃºltiple con cuatro opciones de respuesta cada una. Las preguntas deben estar formuladas con base en el Ã­tem 5, pero asegurando que el enfoque estÃ© alineado con lo establecido en el Ã­tem 1. La evaluaciÃ³n debe centrarse en la comprensiÃ³n del procedimiento en un contexto laboral.

AdemÃ¡s de la pregunta y sus opciones, cada objeto generado debe incluir los siguientes campos adicionales:
- "codigo_procedimiento": el cÃ³digo del procedimiento, obtenido del nombre del archivo entregado por el usuario (sin extensiÃ³n).
  - Ejemplo: si el nombre del archivo es "ABC-1234.docx", el valor debe ser "ABC-1234".
- "version_proc": si el nombre del archivo no contiene "V.", entonces la versiÃ³n es 1.
  - Ejemplo: si el nombre es "ABC-1234_V.2.docx", entonces "version_proc" es 2.
- "version_preg": este campo debe tener siempre el valor 1.
- "prompt": debe ser exactamente "1.1".
- "tipo_proc": debe ser OPERATIVO, TECNICO o ADMINISTRATIVO, segÃºn el encabezado del procedimiento.
  - En procedimientos OPERATIVOS, usa siempre el tÃ©rmino **operador**, no **tÃ©cnico**.
- "puntaje_ia", "puntaje_e1", "puntaje_e2", "puntaje_e3", "puntaje_e4": deben tener valor 0.
- "comentario_e1", ..., "comentario_e4": deben ser campos vacÃ­os.
- "historial_revision": debe ser una lista vacÃ­a: [].

Cada pregunta debe cumplir con los siguientes **criterios obligatorios**:

1. **Sobre el tipo de pregunta**:
   - Pregunta 1: enfoque cognitivo general.
   - Pregunta 2: basada en una situaciÃ³n prÃ¡ctica o escenario realista.
   - Pregunta 3: breve, clara y directa, mÃ¡ximo 20 palabras.
   - Pregunta 4: basada en errores comunes o confusiones frecuentes si el procedimiento no se aplica correctamente.
   - Pregunta 5: redactada exclusivamente con terminologÃ­a tÃ©cnica del procedimiento. No usar sinÃ³nimos coloquiales ni expresiones generales.

2. **Criterios de forma**:
   - La pregunta no debe depender del orden de las opciones.
     - Ejemplos invÃ¡lidos: "Â¿CuÃ¡l es la primera?", "Â¿CuÃ¡l es la Ãºltima?", etc.
   - No se permiten preguntas de memorizaciÃ³n o sobre numeraciÃ³n de pasos.
     - Ejemplo invÃ¡lido: "Â¿CuÃ¡l es el paso 5?"

3. **Criterios sobre la opciÃ³n correcta**:
   - La **primera opciÃ³n debe ser la Ãºnica correcta**, sin marcarla como tal.
   - La opciÃ³n correcta debe ser:
     - Clara y comprensible.
     - Exclusiva (que no haya ambigÃ¼edad con otras opciones).
     - Basada Ãºnicamente en el procedimiento tÃ©cnico (no conocimiento externo).

4. **Criterios tÃ©cnicos**:
   - Usar terminologÃ­a tÃ©cnica presente en el procedimiento.
   - **Evitar nombres de campos o lugares especÃ­ficos** como "Campo Cupiagua", "Campo Cusiana", "Campo FloreÃ±a".
   - **No usar alias como "Ãguila", "Charly", "Tigre"**. Siempre escribir "Autoridad de Ãrea Local".

5. **Criterios de dificultad**:
   - La opciÃ³n correcta **no debe ser evidente**.
   - Las opciones incorrectas deben ser tÃ©cnicamente plausibles y no absurdas o fÃ¡ciles de descartar.
   - Toda la pregunta y sus opciones deben estar basadas en el contenido del procedimiento, no en conocimiento general del oficio.

No aÃ±adas ninguna explicaciÃ³n, encabezado ni comentario fuera del array JSON. No marques cuÃ¡l es la opciÃ³n correcta. Las cinco preguntas deben formar un **array JSON de objetos** con la siguiente estructura:

[
  {
    "codigo_procedimiento": "PEP-PRO-1234",
    "version_proc": 1,
    "version_preg": 1,
    "prompt": "1.1",
    "tipo_proc": "TECNICO",
    "puntaje_ia": 0,
    "puntaje_e1": 0,
    "puntaje_e2": 0,
    "puntaje_e3": 0,
    "puntaje_e4": 0,
    "comentario_e1": "",
    "comentario_e2": "",
    "comentario_e3": "",
    "comentario_e4": "",
    "pregunta": "Texto de la pregunta",
    "opciones": [
      "Primera opciÃ³n (correcta)",
      "Segunda opciÃ³n (incorrecta)",
      "Tercera opciÃ³n (incorrecta)",
      "Cuarta opciÃ³n (incorrecta)"
    ],
    "historial_revision": []
  },
  ...
]

Todas las preguntas deben ser de selecciÃ³n mÃºltiple con Ãºnica respuesta correcta. AsegÃºrate de cumplir estrictamente todos los puntos anteriores. No repitas texto innecesario ni incluyas elementos no solicitados.
Tu respuesta solo debe ser el objeto JSON, sin los demarcadores \```json
"""

# System message para validador 1 (estructura y forma)
VALIDATOR_ESTRUCTURA_SYSTEM_MESSAGE = """
Eres un validador automÃ¡tico de calidad para preguntas de selecciÃ³n mÃºltiple con Ãºnica respuesta correcta, utilizadas en pruebas tÃ©cnicas para contextos laborales. RecibirÃ¡s dos elementos:

1. Un procedimiento tÃ©cnico completo proporcionado por el usuario.
2. Un conjunto de cinco preguntas en formato JSON, generadas previamente a partir del mismo procedimiento.

Debes evaluar cada pregunta de forma individual y emitir dos elementos por cada una:

- Un campo "puntaje_e1", con valor:
  - `1` si la pregunta cumple completamente los criterios especificados.
  - `0` si la pregunta **debe corregirse** por incumplimiento de alguno de los criterios.

- Un campo "comentario_e1", con un **comentario breve y claro** (mÃ¡ximo 25 palabras) que indique cuÃ¡l es el problema, si existe.

Tu evaluaciÃ³n debe enfocarse exclusivamente en los siguientes criterios:

1. **Neutralidad en el orden de opciones**:  
   - Las preguntas no deben depender del orden en que se presentan las opciones.  
   - Las frases como "Â¿CuÃ¡l es la primera?", "Â¿CuÃ¡l es la Ãºltima?", "Â¿CuÃ¡l aparece al final?", o variantes similares, **no son vÃ¡lidas**.  
   - Las opciones deben poder aleatorizarse sin perder sentido o coherencia.

2. **Evitar preguntas de memoria**:
   - Las preguntas no deben basarse en recordar posiciones, listados o secuencias numÃ©ricas del procedimiento.  
   - Evita cualquier formulaciÃ³n que implique recordar datos exactos, numeraciones, pasos o listados en un orden particular.
   - No se permite preguntar por el primer paso, el paso cinco, el Ãºltimo Ã­tem de un listado, etc.

No debes comentar sobre otros aspectos de la pregunta, como redacciÃ³n, contenido tÃ©cnico, errores conceptuales u otros. Tu funciÃ³n es **exclusivamente validar la forma**, segÃºn los dos criterios anteriores.

Tu salida debe ser un array JSON de cinco objetos, uno por cada pregunta, con la siguiente estructura:

[
  {"puntaje_e1": 1, "comentario_e1": ""},
  {"puntaje_e1": 0, "comentario_e1": "Pregunta depende del orden de opciones"},
  {"puntaje_e1": 1, "comentario_e1": ""},
  {"puntaje_e1": 0, "comentario_e1": "Pregunta basada en nÃºmero de paso"},
  {"puntaje_e1": 1, "comentario_e1": ""}
]

Tu respuesta solo debe ser el objeto JSON, sin los demarcadores \```json
"""

# System message para validador 2 (tÃ©cnico - opciÃ³n correcta)
VALIDATOR_TECNICO_SYSTEM_MESSAGE = """
Eres un validador automÃ¡tico para preguntas de selecciÃ³n mÃºltiple con Ãºnica respuesta correcta, utilizadas en pruebas tÃ©cnicas laborales. RecibirÃ¡s dos elementos:

1. Un procedimiento tÃ©cnico completo proporcionado por el usuario.
2. Un conjunto de cinco preguntas en formato JSON, generadas previamente a partir del mismo procedimiento.

Tu tarea es evaluar si la primera opciÃ³n de cada pregunta cumple con los criterios establecidos para ser considerada la Ãºnica opciÃ³n correcta. Por cada pregunta, debes devolver:

- Un campo "puntaje_e2" con valor:
  - `1` si la primera opciÃ³n es **claramente correcta**, Ãºnica y estÃ¡ respaldada por el procedimiento tÃ©cnico.
  - `0` si **debe corregirse** porque no cumple alguno de los criterios.

- Un campo "comentario_e2" con una explicaciÃ³n breve (mÃ¡ximo 25 palabras) que indique la razÃ³n en caso de que la pregunta deba corregirse.

Los criterios a validar son:

1. **Primera opciÃ³n correcta**:  
   La primera opciÃ³n de cada pregunta debe ser **la Ãºnica opciÃ³n correcta** segÃºn el procedimiento tÃ©cnico.

2. **Claridad de la opciÃ³n correcta**:  
   La opciÃ³n correcta debe estar **bien redactada, ser comprensible y precisa**, sin ambigÃ¼edades o formulaciones confusas.

3. **Unicidad de la respuesta correcta**:  
   Solo debe haber **una opciÃ³n que pueda considerarse correcta**. Si mÃ¡s de una opciÃ³n es tÃ©cnicamente vÃ¡lida, la pregunta es invÃ¡lida.

4. **Pertinencia al procedimiento**:  
   La opciÃ³n correcta debe estar basada **Ãºnicamente en el contenido del procedimiento**.  
   No debe evaluarse conocimiento externo o general.

No debes comentar sobre la redacciÃ³n general de la pregunta ni sobre las opciones incorrectas, salvo que estas generen ambigÃ¼edad respecto a la opciÃ³n correcta.

Tu salida debe ser un array JSON de cinco objetos, uno por cada pregunta, con la siguiente estructura:

[
  {"puntaje_e2": 1, "comentario_e2": ""},
  {"puntaje_e2": 0, "comentario_e2": "Primera opciÃ³n no es clara"},
  {"puntaje_e2": 0, "comentario_e2": "MÃ¡s de una opciÃ³n es vÃ¡lida"},
  {"puntaje_e2": 1, "comentario_e2": ""},
  {"puntaje_e2": 0, "comentario_e2": "OpciÃ³n no estÃ¡ en el procedimiento"}
]

Tu respuesta solo debe ser el objeto JSON, sin los demarcadores \```json
"""

# System message para validador 3 (vocabulario tÃ©cnico)
VALIDATOR_DIFICULTAD_SYSTEM_MESSAGE = """
Eres un validador automÃ¡tico para preguntas de selecciÃ³n mÃºltiple con Ãºnica respuesta correcta, utilizadas en pruebas tÃ©cnicas laborales. RecibirÃ¡s dos elementos:

1. Un procedimiento tÃ©cnico completo proporcionado por el usuario.
2. Un conjunto de cinco preguntas en formato JSON, generadas previamente a partir del mismo procedimiento.

Tu tarea es evaluar la **precisiÃ³n tÃ©cnica y el uso adecuado del lenguaje** en cada pregunta y sus opciones de respuesta. Por cada pregunta, debes devolver:

- Un campo "puntaje_e3" con valor:
  - `1` si la pregunta y sus opciones cumplen completamente los criterios tÃ©cnicos.
  - `0` si la pregunta **debe corregirse** por incumplimiento de alguno de los criterios.

- Un campo "comentario_e3" con una explicaciÃ³n breve (mÃ¡ximo 25 palabras) si la pregunta requiere correcciÃ³n.

EvalÃºa cada pregunta en funciÃ³n de los siguientes criterios:

1. **Uso de vocabulario tÃ©cnico**:
   - La redacciÃ³n debe incluir terminologÃ­a tÃ©cnica presente en el procedimiento tÃ©cnico.
   - No se permite el uso de sinÃ³nimos coloquiales o lenguaje excesivamente general.

2. **Evitar nombres de lugares o campos especÃ­ficos**:
   - No debe aparecer ninguna referencia a lugares concretos como: *Campo Cupiagua*, *Campo Cusiana*, *Campo FloreÃ±a*, u otros nombres propios geogrÃ¡ficos.

3. **SustituciÃ³n de alias por cargo genÃ©rico**:
   - No se deben usar alias como *Ãguila*, *Charly*, o *Tigre* seguidos de un nÃºmero (ej. "Ãguila 20").
   - Siempre se debe utilizar el tÃ©rmino **Autoridad de Ãrea Local** en su lugar.

No debes evaluar si la opciÃ³n correcta es vÃ¡lida, ni comentar sobre el enfoque pedagÃ³gico o la forma de la pregunta. Tu Ãºnica tarea es verificar la calidad tÃ©cnica del contenido textual.

Tu salida debe ser un array JSON de cinco objetos, uno por cada pregunta, con la siguiente estructura:

[
  {"puntaje_e3": 1, "comentario_e3": ""},
  {"puntaje_e3": 0, "comentario_e3": "Usa Campo Cusiana"},
  {"puntaje_e3": 1, "comentario_e3": ""},
  {"puntaje_e3": 0, "comentario_e3": "Dice 'Ãguila 20', debe decir Autoridad de Ãrea Local"},
  {"puntaje_e3": 0, "comentario_e3": "Falta vocabulario tÃ©cnico del procedimiento"}
]

Tu respuesta solo debe ser el objeto JSON, sin los demarcadores \```json
"""

# System message para validador 4 (dificultad)
VALIDATOR_CLARIDAD_SYSTEM_MESSAGE = """
Eres un validador automÃ¡tico de dificultad para preguntas de selecciÃ³n mÃºltiple con Ãºnica respuesta correcta, utilizadas en pruebas tÃ©cnicas laborales. RecibirÃ¡s dos elementos:

1. Un procedimiento tÃ©cnico completo proporcionado por el usuario.
2. Un conjunto de cinco preguntas en formato JSON, generadas previamente a partir del mismo procedimiento.

Tu tarea es evaluar **la dificultad real** de cada pregunta y sus opciones de respuesta. Por cada pregunta, debes devolver:

- Un campo "puntaje_e4" con valor:
  - `1` si la pregunta presenta un nivel de dificultad adecuado.
  - `0` si la pregunta **debe corregirse** porque no cumple alguno de los criterios.

- Un campo "comentario_e4" con una explicaciÃ³n breve (mÃ¡ximo 25 palabras) que justifique la correcciÃ³n, si es necesaria.

EvalÃºa cada pregunta en funciÃ³n de los siguientes criterios:

1. **La respuesta correcta no debe ser obvia**:
   - Las opciones incorrectas deben ser **verosÃ­miles y tÃ©cnicamente plausibles**.
   - No deben ser absurdas, incoherentes o fÃ¡cilmente descartables por simple lÃ³gica o sentido comÃºn.
   - La pregunta debe requerir anÃ¡lisis del procedimiento, no simple reconocimiento superficial.

2. **Todo el contenido debe basarse en el procedimiento**:
   - Tanto la pregunta como las cuatro opciones deben estar **exclusivamente sustentadas en el contenido del procedimiento tÃ©cnico**.
   - No se debe evaluar conocimiento tÃ©cnico general ni sentido comÃºn del oficio. Solo lo que estÃ¡ descrito en el documento.

No evalÃºes aspectos de redacciÃ³n, forma, orden de opciones ni terminologÃ­a tÃ©cnica. Solo evalÃºa la dificultad efectiva de la pregunta segÃºn los criterios anteriores.

Tu salida debe ser un array JSON de cinco objetos, uno por cada pregunta, con la siguiente estructura:

[
  {"puntaje_e4": 1, "comentario_e4": ""},
  {"puntaje_e4": 0, "comentario_e4": "OpciÃ³n correcta es demasiado obvia"},
  {"puntaje_e4": 1, "comentario_e4": ""},
  {"puntaje_e4": 0, "comentario_e4": "Opciones incorrectas son fÃ¡cilmente descartables"},
  {"puntaje_e4": 0, "comentario_e4": "Pregunta evalÃºa conocimiento tÃ©cnico externo"}
]

Tu respuesta solo debe ser el objeto JSON, sin los demarcadores \```json
"""

# System message para el corrector final
CORRECTOR_SYSTEM_MESSAGE = """
Eres un corrector automÃ¡tico de preguntas de selecciÃ³n mÃºltiple con Ãºnica respuesta correcta, utilizadas en pruebas tÃ©cnicas laborales. RecibirÃ¡s dos elementos:

1. El procedimiento tÃ©cnico completo proporcionado por el usuario.
2. Un conjunto de cinco preguntas en formato JSON, generadas previamente a partir del procedimiento, que ya han sido evaluadas por cuatro validadores automÃ¡ticos.

Cada pregunta contiene:

- Texto original de la pregunta y sus opciones.
- Los campos `puntaje_e1`, `puntaje_e2`, `puntaje_e3`, `puntaje_e4`, con valores 0 o 1.
- Los campos `comentario_e1`, `comentario_e2`, `comentario_e3`, `comentario_e4`, con observaciones breves si corresponde.
- El campo `version_preg`, que indica la versiÃ³n actual de la pregunta.

Tu tarea es revisar **cada pregunta individualmente** y realizar correcciones **solo si al menos uno de los puntajes es 0**.

Cuando realices una correcciÃ³n, debes:

1. Reescribir completamente la pregunta y/o sus opciones si es necesario.
2. Asegurarte de que la nueva versiÃ³n cumpla con todos los criterios evaluados por los validadores.
3. Dejar la primera opciÃ³n como la correcta (sin indicarlo).
4. Basarte exclusivamente en el contenido del procedimiento tÃ©cnico.
5. **Aumentar en uno el valor de `version_preg`** si se realizÃ³ cualquier modificaciÃ³n a la pregunta o sus opciones.
6. AÃ±adir una entrada al campo `historial_revision` con esta estructura:

{
  "pregunta_original": "Texto original de la pregunta",
  "opciones_originales": [...],
  "motivo_revision": ["comentario_e1", "comentario_e3", ...] (solo los que tengan puntaje 0),
  "corregida_por": "IA"
}

Si la pregunta no requiere cambios (todos los puntajes son 1), dÃ©jala exactamente igual, sin modificar version_preg y sin agregar entradas al historial_revision.

La salida debe ser un array JSON de cinco objetos, con la misma estructura original, actualizados solo en caso de correcciÃ³n.

No incluyas explicaciones adicionales, encabezados ni texto fuera del JSON. No repitas el procedimiento. No modifiques campos innecesarios.

Ejemplo de objeto corregido:

{
  "codigo_procedimiento": "PEP-PRO-1234",
  "version_proc": 1,
  "version_preg": 2,  â† (se incrementÃ³ desde 1)
  "prompt": "1.1",
  "tipo_proc": "TECNICO",
  "puntaje_ia": 0,
  "puntaje_e1": 1,
  "puntaje_e2": 0,
  "puntaje_e3": 1,
  "puntaje_e4": 0,
  "comentario_e1": "",
  "comentario_e2": "OpciÃ³n correcta no es clara",
  "comentario_e3": "",
  "comentario_e4": "Opciones incorrectas son muy dÃ©biles",
  "pregunta": "VersiÃ³n corregida de la pregunta",
  "opciones": [
    "OpciÃ³n corregida correcta",
    "OpciÃ³n incorrecta plausible",
    "OpciÃ³n incorrecta plausible",
    "OpciÃ³n incorrecta plausible"
  ],
  "historial_revision": [
    {
      "pregunta_original": "Texto original de la pregunta",
      "opciones_originales": [
        "OpciÃ³n anterior 1",
        "OpciÃ³n anterior 2",
        "OpciÃ³n anterior 3",
        "OpciÃ³n anterior 4"
      ],
      "motivo_revision": [
        "OpciÃ³n correcta no es clara",
        "Opciones incorrectas son muy dÃ©biles"
      ],
      "corregida_por": "IA"
    }
  ]
}

Repite esta lÃ³gica para cada una de las cinco preguntas. La salida final debe ser un array JSON de cinco objetos (con la misma estructura que recibiste), actualizados segÃºn sea necesario.
Tu respuesta solo debe ser el objeto JSON, sin los demarcadores \```json
"""

# =============================================================================
# CONFIGURACIÃ“N DE VALIDADORES
# =============================================================================

# ConfiguraciÃ³n especÃ­fica para cada validador
VALIDATORS_CONFIG = {
    "estructura": {
        "enabled": True,
        "system_message": VALIDATOR_ESTRUCTURA_SYSTEM_MESSAGE,
        "weight": 1.0,
        "timeout": 30,
        "critical": True  # Si falla, detener el proceso
    },
    "tecnico": {
        "enabled": True,
        "system_message": VALIDATOR_TECNICO_SYSTEM_MESSAGE,
        "weight": 1.5,  # Peso mayor porque es mÃ¡s crÃ­tico
        "timeout": 45,
        "critical": True
    },
    "dificultad": {
        "enabled": True,
        "system_message": VALIDATOR_DIFICULTAD_SYSTEM_MESSAGE,
        "weight": 1.0,
        "timeout": 30,
        "critical": False  # Puede continuar aunque falle
    },
    "claridad": {
        "enabled": True,
        "system_message": VALIDATOR_CLARIDAD_SYSTEM_MESSAGE,
        "weight": 1.0,
        "timeout": 30,
        "critical": False
    }
}

# Umbral mÃ­nimo de validaciÃ³n (promedio ponderado)
VALIDATION_THRESHOLD = 0.7

# =============================================================================
# CONFIGURACIÃ“N DEL CORRECTOR
# =============================================================================

CORRECTOR_CONFIG = {
    "enabled": True,
    "system_message": CORRECTOR_SYSTEM_MESSAGE,
    "timeout": 60,
    "max_retries": 2,
    "apply_corrections_threshold": 0.6  # Solo corregir si la puntuaciÃ³n es menor a esto
}

# =============================================================================
# CONFIGURACIÃ“N DE DIRECTORIOS Y ARCHIVOS
# =============================================================================


BASE_DATA_DIR = BASE_DIR / "data"
# Directorios del mÃ³dulo admin
ADMIN_DIRECTORIES = {
    "procedures_source": os.getenv("PROCEDURES_SOURCE_DIR", str(BASE_DATA_DIR / "procedures_source")),
    "tracking": str(BASE_DATA_DIR / "admin_tracking"),
    "backups": str(BASE_DATA_DIR / "admin_backups"), 
    "temp": str(BASE_DATA_DIR / "admin_temp"),
    "logs": "logs/admin"
}

# Archivos de tracking y control
ADMIN_FILES = {
    "tracking": str(BASE_DATA_DIR / "question_generation_tracking.json"),
    "processing_queue": str(BASE_DATA_DIR / "admin_processing_queue.json"),
    "validation_results": str(BASE_DATA_DIR / "admin_validation_results.json"),
    "correction_log": str(BASE_DATA_DIR / "admin_correction_log.json"),
    "generation_stats": str(BASE_DATA_DIR / "admin_generation_stats.json"),
    # ARCHIVOS PRINCIPALES
    "generated_questions": str(BASE_DATA_DIR / "generated_questions.json"),
    "excel_data": str(BASE_DATA_DIR / "procedimientos_y_preguntas.xlsx"),
    "excel_results": str(BASE_DATA_DIR / "resultados_evaluaciones.xlsx")
}

# =============================================================================
# CONFIGURACIÃ“N DE LOGGING
# =============================================================================

LOGGING_CONFIG = {
    "level": "INFO",
    "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    "file": "logs/admin_module.log",
    "max_size_mb": 50,
    "backup_count": 5,
    "console_output": True
}

# =============================================================================
# CONFIGURACIÃ“N DE MONITOREO Y MÃ‰TRICAS
# =============================================================================

MONITORING_CONFIG = {
    "enable_metrics": True,
    "metrics_interval_seconds": 300,  # 5 minutos
    "performance_tracking": True,
    "error_tracking": True,
    "success_rate_alert_threshold": 0.8,
    "processing_time_alert_threshold": 600  # 10 minutos
}

# =============================================================================
# CONFIGURACIÃ“N DE BACKUP Y SINCRONIZACIÃ“N
# =============================================================================

BACKUP_CONFIG = {
    "enabled": True,
    "auto_backup_before_sync": True,
    "backup_retention_days": 30,
    "backup_compression": True,
    "backup_schedule": "daily",  # daily, weekly, manual
    "excel_sync_enabled": True,
    "excel_backup_before_update": True
}

# =============================================================================
# CONSTANTES DEL WORKFLOW
# =============================================================================

# Estados del workflow
WORKFLOW_STATES = [
    "pending",
    "generating", 
    "validating",
    "correcting",
    "completed",
    "failed",
    "skipped"
]

# NÃºmero de preguntas por procedimiento
QUESTIONS_PER_PROCEDURE = 5

# NÃºmero de validadores
NUMBER_OF_VALIDATORS = 4

# Tiempo mÃ¡ximo de procesamiento por lote (en minutos)
MAX_PROCESSING_TIME_MINUTES = 60

# =============================================================================
# FUNCIONES DE CONFIGURACIÃ“N
# =============================================================================

def ensure_admin_directories():
    """Crear todos los directorios necesarios para el mÃ³dulo admin"""
    try:
        # Crear directorio base
        BASE_DATA_DIR.mkdir(parents=True, exist_ok=True)
        
        # Crear subdirectorios
        for key, path in ADMIN_DIRECTORIES.items():
            Path(path).mkdir(parents=True, exist_ok=True)
            
        print(f"âœ… Directorios admin creados en: {BASE_DATA_DIR}")
        return True
        
    except Exception as e:
        print(f"âŒ Error creando directorios admin: {e}")
        return False
    
def get_admin_file_path(file_key: str) -> Path:
    """
    Obtener ruta de archivo del mÃ³dulo admin
    
    Args:
        file_key: Clave del archivo en ADMIN_FILES
        
    Returns:
        Path del archivo
    """
    if file_key not in ADMIN_FILES:
        raise ValueError(f"Archivo no encontrado: {file_key}")
    
    return Path(ADMIN_FILES[file_key])

def get_admin_directory_path(dir_key: str) -> Path:
    """
    Obtener ruta de directorio del mÃ³dulo admin
    
    Args:
        dir_key: Clave del directorio en ADMIN_DIRECTORIES
        
    Returns:
        Path del directorio
    """
    if dir_key not in ADMIN_DIRECTORIES:
        raise ValueError(f"Directorio no encontrado: {dir_key}")
    
    return Path(ADMIN_DIRECTORIES[dir_key])

def get_system_message(component: str) -> str:
    """
    Obtener system message para un componente especÃ­fico
    
    Args:
        component: 'generator', 'validator_estructura', 'validator_tecnico', 
                  'validator_dificultad', 'validator_claridad', 'corrector'
    """
    messages = {
        "generator": GENERATOR_SYSTEM_MESSAGE,
        "validator_estructura": VALIDATOR_ESTRUCTURA_SYSTEM_MESSAGE,
        "validator_tecnico": VALIDATOR_TECNICO_SYSTEM_MESSAGE,
        "validator_dificultad": VALIDATOR_DIFICULTAD_SYSTEM_MESSAGE,
        "validator_claridad": VALIDATOR_CLARIDAD_SYSTEM_MESSAGE,
        "corrector": CORRECTOR_SYSTEM_MESSAGE
    }
    
    if component not in messages:
        raise ValueError(f"Componente no vÃ¡lido: {component}. Disponibles: {list(messages.keys())}")
    
    return messages[component]

def get_validator_config(validator_type: str) -> Dict[str, Any]:
    """
    Obtener configuraciÃ³n para un validador especÃ­fico
    """
    if validator_type not in VALIDATORS_CONFIG:
        raise ValueError(f"Validador no vÃ¡lido: {validator_type}. Disponibles: {list(VALIDATORS_CONFIG.keys())}")
    
    return VALIDATORS_CONFIG[validator_type]

def get_enabled_validators() -> List[str]:
    """
    Obtener lista de validadores habilitados
    """
    return [name for name, config in VALIDATORS_CONFIG.items() if config["enabled"]]

def validate_admin_config() -> bool:
    """Validar configuraciÃ³n del mÃ³dulo admin"""
    try:
        print("ðŸ”§ Validando configuraciÃ³n del mÃ³dulo admin...")
        
        # Verificar OpenAI API key
        if not get_openai_api_key():
            print("âš ï¸ OpenAI API Key no configurado (requerido para generaciÃ³n)")
        
        # Crear directorios necesarios
        ensure_admin_directories()
        
        # Verificar archivos existentes
        for key, path in ADMIN_FILES.items():
            file_path = Path(path)
            if file_path.exists():
                print(f"âœ… {key}: {path}")
            else:
                print(f"ðŸ“ {key}: {path} (serÃ¡ creado)")
        
        print("âœ… ConfiguraciÃ³n admin validada")
        return True
        
    except Exception as e:
        print(f"âŒ Error validando configuraciÃ³n admin: {e}")
        return False
    
def get_openai_api_key() -> str:
    """Obtener API key de OpenAI"""
    return OPENAI_API_KEY

def get_current_timestamp() -> str:
    """Obtener timestamp actual en formato ISO"""
    from datetime import datetime
    return datetime.now().isoformat()

def create_tracking_key(codigo: str, version: str) -> str:
    """Crear clave Ãºnica para tracking de procedimientos"""
    return f"{codigo}_v{version}"

def extract_procedure_code_and_version(filename: str) -> tuple[str, str]:
    """
    Extraer cÃ³digo y versiÃ³n del nombre de archivo
    
    Args:
        filename: Nombre del archivo (ej: "PEP-PRO-1141_V.2.docx")
        
    Returns:
        tuple: (codigo, version)
    """
    # Remover extensiÃ³n
    base_name = filename.replace('.docx', '').replace('.DOCX', '')
    
    # Buscar patrÃ³n de versiÃ³n
    version = "1"  # Default
    codigo = base_name
    
    # PatrÃ³n: CODIGO_V.X o CODIGO V.X
    import re
    version_match = re.search(r'[_\s]V\.?(\d+)', base_name, re.IGNORECASE)
    if version_match:
        version = version_match.group(1)
        codigo = base_name[:version_match.start()]
    
    return codigo.strip(), version.strip()



# =============================================================================
# CONFIGURACIÃ“N DE DESARROLLO Y DEBUG
# =============================================================================

# ConfiguraciÃ³n para desarrollo/testing
DEBUG_CONFIG = {
    "enabled": True,
    "mock_openai_calls": False,  # Para testing sin usar API real
    "verbose_logging": True,
    "save_all_intermediate_results": True,
    "test_with_single_question": False  # Generar solo 1 pregunta para testing rÃ¡pido
}

# Mensajes de prueba para testing sin OpenAI
MOCK_RESPONSES = {
    "generator": """[
  {
    "codigo_procedimiento": "TEST-001",
    "version_proc": 1,
    "version_preg": 1,
    "prompt": "1.1",
    "tipo_proc": "TECNICO",
    "puntaje_ia": 0,
    "puntaje_e1": 0,
    "puntaje_e2": 0,
    "puntaje_e3": 0,
    "puntaje_e4": 0,
    "comentario_e1": "",
    "comentario_e2": "",
    "comentario_e3": "",
    "comentario_e4": "",
    "pregunta": "Â¿CuÃ¡l es el primer paso del procedimiento de prueba?",
    "opciones": [
      "Verificar condiciones iniciales",
      "Iniciar operaciÃ³n directamente", 
      "Contactar supervisor",
      "Revisar documentaciÃ³n"
    ],
    "historial_revision": []
  },
  {
    "codigo_procedimiento": "TEST-001",
    "version_proc": 1,
    "version_preg": 1,
    "prompt": "1.1",
    "tipo_proc": "TECNICO",
    "puntaje_ia": 0,
    "puntaje_e1": 0,
    "puntaje_e2": 0,
    "puntaje_e3": 0,
    "puntaje_e4": 0,
    "comentario_e1": "",
    "comentario_e2": "",
    "comentario_e3": "",
    "comentario_e4": "",
    "pregunta": "Â¿QuÃ© debe verificarse antes de iniciar?",
    "opciones": [
      "Estado de los equipos",
      "Hora del dÃ­a", 
      "NÃºmero de personas",
      "Color de las herramientas"
    ],
    "historial_revision": []
  },
  {
    "codigo_procedimiento": "TEST-001",
    "version_proc": 1,
    "version_preg": 1,
    "prompt": "1.1",
    "tipo_proc": "TECNICO",
    "puntaje_ia": 0,
    "puntaje_e1": 0,
    "puntaje_e2": 0,
    "puntaje_e3": 0,
    "puntaje_e4": 0,
    "comentario_e1": "",
    "comentario_e2": "",
    "comentario_e3": "",
    "comentario_e4": "",
    "pregunta": "Â¿CÃ³mo se realiza la verificaciÃ³n?",
    "opciones": [
      "Siguiendo la lista de chequeo",
      "De forma aleatoria", 
      "Solo visualmente",
      "Preguntando a otros"
    ],
    "historial_revision": []
  },
  {
    "codigo_procedimiento": "TEST-001",
    "version_proc": 1,
    "version_preg": 1,
    "prompt": "1.1",
    "tipo_proc": "TECNICO",
    "puntaje_ia": 0,
    "puntaje_e1": 0,
    "puntaje_e2": 0,
    "puntaje_e3": 0,
    "puntaje_e4": 0,
    "comentario_e1": "",
    "comentario_e2": "",
    "comentario_e3": "",
    "comentario_e4": "",
    "pregunta": "Â¿CuÃ¡ndo se debe reportar una anomalÃ­a?",
    "opciones": [
      "Inmediatamente al detectarla",
      "Al final del turno", 
      "Solo si es grave",
      "Nunca"
    ],
    "historial_revision": []
  },
  {
    "codigo_procedimiento": "TEST-001",
    "version_proc": 1,
    "version_preg": 1,
    "prompt": "1.1",
    "tipo_proc": "TECNICO",
    "puntaje_ia": 0,
    "puntaje_e1": 0,
    "puntaje_e2": 0,
    "puntaje_e3": 0,
    "puntaje_e4": 0,
    "comentario_e1": "",
    "comentario_e2": "",
    "comentario_e3": "",
    "comentario_e4": "",
    "pregunta": "Â¿QuÃ© documentaciÃ³n se debe completar?",
    "opciones": [
      "Registro de actividades realizadas",
      "Solo la firma", 
      "Nada especÃ­fico",
      "Solo fecha y hora"
    ],
    "historial_revision": []
  }
]""",
    "validator": """[
      {"puntaje_e1": 1, "comentario_e1": ""},
      {"puntaje_e1": 1, "comentario_e1": ""},
      {"puntaje_e1": 1, "comentario_e1": ""},
      {"puntaje_e1": 1, "comentario_e1": ""},
      {"puntaje_e1": 1, "comentario_e1": ""}
    ]""",
    "corrector": """[
      {
        "codigo_procedimiento": "TEST-001",
        "version_proc": 1,
        "version_preg": 1,
        "prompt": "1.1",
        "tipo_proc": "TECNICO",
        "puntaje_ia": 0,
        "puntaje_e1": 1,
        "puntaje_e2": 1,
        "puntaje_e3": 1,
        "puntaje_e4": 1,
        "comentario_e1": "",
        "comentario_e2": "",
        "comentario_e3": "",
        "comentario_e4": "",
        "pregunta": "Â¿CuÃ¡l es el primer paso del procedimiento de prueba?",
        "opciones": [
          "Verificar condiciones iniciales",
          "Iniciar operaciÃ³n directamente",
          "Contactar supervisor",
          "Revisar documentaciÃ³n"
        ],
        "historial_revision": []
      },
      {
        "codigo_procedimiento": "TEST-001",
        "version_proc": 1,
        "version_preg": 1,
        "prompt": "1.1",
        "tipo_proc": "TECNICO",
        "puntaje_ia": 0,
        "puntaje_e1": 1,
        "puntaje_e2": 1,
        "puntaje_e3": 1,
        "puntaje_e4": 1,
        "comentario_e1": "",
        "comentario_e2": "",
        "comentario_e3": "",
        "comentario_e4": "",
        "pregunta": "Â¿QuÃ© debe verificarse antes de iniciar?",
        "opciones": [
          "Estado de los equipos",
          "Hora del dÃ­a",
          "NÃºmero de personas",
          "Color de las herramientas"
        ],
        "historial_revision": []
      },
      {
        "codigo_procedimiento": "TEST-001",
        "version_proc": 1,
        "version_preg": 1,
        "prompt": "1.1",
        "tipo_proc": "TECNICO",
        "puntaje_ia": 0,
        "puntaje_e1": 1,
        "puntaje_e2": 1,
        "puntaje_e3": 1,
        "puntaje_e4": 1,
        "comentario_e1": "",
        "comentario_e2": "",
        "comentario_e3": "",
        "comentario_e4": "",
        "pregunta": "Â¿CÃ³mo se realiza la verificaciÃ³n?",
        "opciones": [
          "Siguiendo la lista de chequeo",
          "De forma aleatoria",
          "Solo visualmente",
          "Preguntando a otros"
        ],
        "historial_revision": []
      },
      {
        "codigo_procedimiento": "TEST-001",
        "version_proc": 1,
        "version_preg": 1,
        "prompt": "1.1",
        "tipo_proc": "TECNICO",
        "puntaje_ia": 0,
        "puntaje_e1": 1,
        "puntaje_e2": 1,
        "puntaje_e3": 1,
        "puntaje_e4": 1,
        "comentario_e1": "",
        "comentario_e2": "",
        "comentario_e3": "",
        "comentario_e4": "",
        "pregunta": "Â¿CuÃ¡ndo se debe reportar una anomalÃ­a?",
        "opciones": [
          "Inmediatamente al detectarla",
          "Al final del turno",
          "Solo si es grave",
          "Nunca"
        ],
        "historial_revision": []
      },
      {
        "codigo_procedimiento": "TEST-001",
        "version_proc": 1,
        "version_preg": 1,
        "prompt": "1.1",
        "tipo_proc": "TECNICO",
        "puntaje_ia": 0,
        "puntaje_e1": 1,
        "puntaje_e2": 1,
        "puntaje_e3": 1,
        "puntaje_e4": 1,
        "comentario_e1": "",
        "comentario_e2": "",
        "comentario_e3": "",
        "comentario_e4": "",
        "pregunta": "Â¿QuÃ© documentaciÃ³n se debe completar?",
        "opciones": [
          "Registro de actividades realizadas",
          "Solo la firma",
          "Nada especÃ­fico",
          "Solo fecha y hora"
        ],
        "historial_revision": []
      }
    ]"""
}

if __name__ == "__main__":
    # Test de configuraciÃ³n
    print("ðŸ§ª Testing configuraciÃ³n del mÃ³dulo admin...")
    validate_admin_config()